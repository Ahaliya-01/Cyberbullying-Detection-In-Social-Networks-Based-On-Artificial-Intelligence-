# -*- coding: utf-8 -*-
"""Copy of Cyber_Bullying_ANN_Nov19_text_prediction_(2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rwzFPyHOm4p8G7T-a39asrt0KVKaM2Mg
"""



from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd   /content/drive/MyDrive/

!ls

# Commented out IPython magic to ensure Python compatibility.
# %cd drive/MyDrive/

# Commented out IPython magic to ensure Python compatibility.
# %cd Cyber_bulling/

"""**IMPORT_LIBRABRIES**"""

import numpy as np
import pandas as pd
from tensorflow.python import keras
from keras.preprocessing import sequence,text
from keras.preprocessing.text import Tokenizer
from keras.models import Sequential
from keras.layers import Dense,Dropout,Embedding,LSTM,Conv1D,GlobalMaxPooling1D,Flatten,MaxPooling1D,GRU,SpatialDropout1D,Bidirectional
from keras.callbacks import EarlyStopping
from keras.utils import to_categorical
from keras.losses import categorical_crossentropy
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import os
print(os.listdir("."))
import seaborn as sns
import re
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.corpus import stopwords
import warnings
warnings.filterwarnings("ignore")

"""**LOADING_DATASET**"""

df=pd.read_csv('cyberbullying_tweets.csv')
df

"""**DATA_PREPROCESSING**"""

df.shape

df.describe()

df.info()

# checking if there is any null data or not
df.isnull().any()

df.isnull().sum()

df.dtypes

df['tweet_text'].value_counts()

df['cyberbullying_type'].value_counts()

import re
def remove_special_character_And_punctuation(text):
    clean_txt = re.sub(r"[^\w\s]","",text)
    return clean_txt
df['tweet_text'] = df['tweet_text'].apply(remove_special_character_And_punctuation)

import nltk
nltk.download('punkt')

def tokenization(text):
    return nltk.word_tokenize(text)

df['Tokens'] = df['tweet_text'].apply(tokenization)

from nltk.corpus import stopwords
nltk.download('stopwords')
stop_words = set(stopwords.words('english'))

def remove_stopword(list_of_word):
    filtered_word = [word  for word in list_of_word if word.lower() not in stop_words]
    return filtered_word

df['Process_Tokens'] = df['Tokens'].apply(remove_stopword)

from nltk.stem import WordNetLemmatizer , PorterStemmer
from nltk.corpus import wordnet
nltk.download('wordnet')

def stemming(tokens):
    stemmer = PorterStemmer()
    stemmed_tokens = [stemmer.stem(token) for token in tokens]
    return stemmed_tokens

df['stemmed_Tokens'] = df['Process_Tokens'].apply(stemming)

def tokens_to_word(li):
    return ' '.join(li)
df['tt'] = df['stemmed_Tokens'].apply(tokens_to_word)

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
df['cyberbullying_type'] = label_encoder.fit_transform(df['cyberbullying_type'])
df['cyberbullying_type']

"""### Get class labels

"""

Labels=list(label_encoder.inverse_transform([0, 1, 2,3,4,5]))

df['cyberbullying_type'].value_counts().index

X = df['tt']
y = df['cyberbullying_type']

df

nltk.download('stopwords')
eng_stops = set(stopwords.words("english"))

from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LogisticRegression
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.feature_extraction.text import CountVectorizer
from sklearn import metrics
cv = CountVectorizer()
X_scaled = cv.fit_transform(X)
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3)

"""**ALGORITHMS**"""

#SVM
from sklearn import svm
svm_class= svm.SVC()
svm_class.fit(X_train,y_train)
y_pred=svm_class.predict(X_test)
Accuracy_Svm=round((metrics.accuracy_score(y_test, y_pred)*100),2)
print('Accuracy: ',Accuracy_Svm,"%")

from sklearn.metrics import classification_report
targets=['class 0','class 1','class 2','class 3','class 4','class 5']
print(classification_report(y_test,y_pred,target_names=targets))

"""**TEXT_PREDICTION**"""

new_review=[["questionni di joke gay rape babe rape"]]
new_review_df= pd.DataFrame(new_review,columns=['new_review'])
new_review_df

new_review_df['new_review']=new_review_df['new_review'].apply(remove_special_character_And_punctuation)
new_review_df

new_review_df['new_review']=new_review_df['new_review'].apply(tokenization)
new_review_df

new_review_df['new_review']=new_review_df['new_review'].apply(remove_stopword)
new_review_df

new_review_df['new_review']=new_review_df['new_review'].apply(stemming)
new_review_df

new_review_df['new_review']=new_review_df['new_review'].apply(tokens_to_word)
new_review_df

newText=df['tt']
new_merged_series=newText.append(new_review_df['new_review'])
new_merged_series.tail(6)

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer()
new_scaled = cv.fit_transform(new_merged_series)


#prediction
new_prediction = svm_class.predict(new_scaled[-1])
print(new_prediction)
if new_prediction[0]==0:
  print("It is type Age")
elif new_prediction[0]==1:
  print("It is type ethnicity")
elif new_prediction[0]==2:
  print("It is type gender")
elif new_prediction[0]==3:
  print("It is type not bullying")
elif new_prediction[0]==4:
  print("It is type other bullying")
else:
  print("It is type religion")

#NAVIE_BAYES
from sklearn.naive_bayes import MultinomialNB
NB=MultinomialNB()
NB.fit(X_train,y_train)
y_pred=NB.predict(X_test)
Accuracy_NB=round((metrics.accuracy_score(y_test, y_pred)*100),2)
print('Accuracy: ',Accuracy_NB,"%")

targets=['class 0','class 1','class 2','class 3','class 4','class 5']
print(classification_report(y_test,y_pred,target_names=targets))

#DECISION_TREE
from sklearn.tree import DecisionTreeClassifier
random_class=DecisionTreeClassifier(criterion='entropy', random_state=0)
random_class.fit(X_train, y_train)
y_pred= random_class.predict(X_test)
Accuracy_DT=round((metrics.accuracy_score(y_test, y_pred)*100),2)
print('Accuracy: ',Accuracy_DT,"%")

targets=['class 0','class 1','class 2','class 3','class 4','class 5']
print(classification_report(y_test,y_pred,target_names=targets))

#RANDOM_FOREST
from sklearn.ensemble import RandomForestClassifier
random_class= RandomForestClassifier(n_estimators= 200, criterion="entropy")
random_class.fit(X_train, y_train)
y_pred= random_class.predict(X_test)
Accuracy_RF=round((metrics.accuracy_score(y_test, y_pred)*100),2)
print('Accuracy: ',Accuracy_RF,"%")

targets=['class 0','class 1','class 2','class 3','class 4','class 5']
print(classification_report(y_test,y_pred,target_names=targets))

#LOGISTIC
from sklearn.linear_model import LogisticRegression
LR_class= LogisticRegression(random_state=0)
LR_class.fit(X_train, y_train)
y_pred = LR_class.predict(X_test)
Accuracy_LR=round((metrics.accuracy_score(y_test, y_pred)*100),2)
print('Accuracy: ',Accuracy_LR,"%")

targets=['class 0','class 1','class 2','class 3','class 4','class 5']
print(classification_report(y_test,y_pred,target_names=targets))

"""**DATA_VISUALIZATION**"""

fig=plt.figure(figsize=(7,7))
colors=("cyan","yellow","crimson","blue","green","red")
wp={'linewidth':2,'edgecolor':"black"}
explode=(0.1,0.1,0.1,0.1,0.1,0.1)
tags=df['cyberbullying_type'].value_counts()
tags.plot(kind='pie',autopct="%1.1f%%",label='',colors=colors,explode=explode,shadow=True,wedgeprops=wp)
plt.legend(title="cyberbullying_type")
plt.title('Distribution of the different cyberbullying type',fontsize='25',fontweight='bold')
plt.show()

sns.countplot(x='cyberbullying_type',data=df)

plt.figure(figsize=(9,6))
acc=[Accuracy_Svm,Accuracy_NB,Accuracy_DT,Accuracy_RF,Accuracy_LR]
alg=['SVM','Naive Bayes Multi','Decision Tree','Random Forest','Logistic']
plt.ylim(60,100)

sns.barplot(x=alg, y=acc,color='crimson')
plt.xticks(rotation='vertical')

plt.xlabel('classification algorithms', fontsize=12)
plt.ylabel('accuracy', fontsize=12)
plt.title("Accuracy Comparison of algorithms")
plt.show()

from sklearn.feature_extraction.text import CountVectorizer


def get_top_n_words(corpus, n=None):
  vec = CountVectorizer().fit(corpus)
  bag_of_words = vec.transform(corpus)
  sum_words = bag_of_words.sum(axis=0)
  words_freq = [(word, sum_words[0, idx])
        for word, idx in vec.vocabulary_.items()]
  words_freq = sorted(words_freq, key=lambda x: x[1],
            reverse=True)
  return words_freq[:n]


common_words = get_top_n_words(df['tt'], 20)
df1 = pd.DataFrame(common_words, columns=['tt', 'cyberbullying_type'])

df1.groupby('tt').sum()['cyberbullying_type'].sort_values(ascending=False).plot(kind='bar',figsize=(10, 6), xlabel="Top Words", ylabel="Count", title="Bar Chart of Top Words Frequency")

from wordcloud import WordCloud,STOPWORDS
def wc(data,bgcolor):
   plt.figure(figsize=(30,30))
   wc=WordCloud(background_color=bgcolor,stopwords=STOPWORDS)
   wc.generate(''.join(data))
   plt.imshow(wc)
   plt.axis("off")
wc(df.tt,'black')

y=to_categorical(df.cyberbullying_type)

df

import matplotlib.pyplot as plt

print(df.columns)

for bully in df['cyberbullying_type'].unique():
    top_50_words=df.tweet_text[df['cyberbullying_type']==bully].str.split(expand=True).stack().value_counts()[:51]
top_50_words

from wordcloud import WordCloud
from wordcloud import STOPWORDS

consolidated = ' '.join(word for word in df['tweet_text'][df['cyberbullying_type'] == 0].astype(str))
wordCloud = WordCloud(width=1600,height=800,random_state=21,max_font_size=110,collocations=False)
plt.figure(figsize=(15, 10))
plt.imshow(wordCloud.generate(consolidated), interpolation='bilinear')
plt.axis('off')
plt.show()

consolidated = ' '.join(word for word in df['tweet_text'][df['cyberbullying_type'] == 1].astype(str))
wordCloud = WordCloud(width=1600,height=800,random_state=21,max_font_size=110,collocations=False)
plt.figure(figsize=(15, 10))
plt.imshow(wordCloud.generate(consolidated), interpolation='bilinear')
plt.axis('off')
plt.show()

consolidated = ' '.join(word for word in df['tweet_text'][df['cyberbullying_type'] == 2].astype(str))
wordCloud = WordCloud(width=1600,height=800,random_state=21,max_font_size=110,collocations=False)
plt.figure(figsize=(15, 10))
plt.imshow(wordCloud.generate(consolidated), interpolation='bilinear')
plt.axis('off')
plt.show()

consolidated = ' '.join(word for word in df['tweet_text'][df['cyberbullying_type'] == 3].astype(str))
wordCloud = WordCloud(width=1600,height=800,random_state=21,max_font_size=110,collocations=False)
plt.figure(figsize=(15, 10))
plt.imshow(wordCloud.generate(consolidated), interpolation='bilinear')
plt.axis('off')
plt.show()

consolidated = ' '.join(word for word in df['tweet_text'][df['cyberbullying_type'] == 4].astype(str))
wordCloud = WordCloud(width=1600,height=800,random_state=21,max_font_size=110,collocations=False)
plt.figure(figsize=(15, 10))
plt.imshow(wordCloud.generate(consolidated), interpolation='bilinear')
plt.axis('off')
plt.show()

consolidated = ' '.join(word for word in df['tweet_text'][df['cyberbullying_type'] == 5].astype(str))
wordCloud = WordCloud(width=1600,height=800,random_state=21,max_font_size=110,collocations=False)
plt.figure(figsize=(15, 10))
plt.imshow(wordCloud.generate(consolidated), interpolation='bilinear')
plt.axis('off')
plt.show()

y

y

print(X_train.shape,y_train.shape)
print(X_test.shape,y_test.shape)

from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer(stop_words='english', min_df=0.0001)

from sklearn.feature_extraction.text import TfidfVectorizer

from scipy.sparse import csr_matrix
from nltk.tokenize import word_tokenize
from nltk import FreqDist

all_words=' '.join(X_train)
all_words=word_tokenize(all_words)
dist=FreqDist(all_words)
num_unique_word=len(dist)
num_unique_word

MAX_REVIEW_LEN=0
for text in X_train:
    word=word_tokenize(text)
    l=len(word)
    MAX_REVIEW_LEN = max(MAX_REVIEW_LEN, l)

MAX_REVIEW_LEN

max_features = num_unique_word
max_words = MAX_REVIEW_LEN
batch_size = 32
epochs = 10
num_classes=6

tokenizer = Tokenizer(num_words=max_features)
tokenizer.fit_on_texts(list(X_train))
X_train = tokenizer.texts_to_sequences(X_train)
X_val = tokenizer.texts_to_sequences(X_test)

X_train[:5]

X_val[:5]

import tensorflow as tf
X_train =  tf.keras.utils.pad_sequences(X_train, maxlen=max_words)
X_val =  tf.keras.utils.pad_sequences(X_val, maxlen=max_words)
print(X_train.shape,X_val.shape)

from keras.models import Sequential
from keras.layers import Dense

model = Sequential()
model.add(Embedding(input_dim=100, output_dim=32, input_length=MAX_REVIEW_LEN))
model.add(Flatten())
model.add(Dense(16, activation="relu"))
model.add(Dense(6, activation="softmax"))
model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])


history = model.fit(X_train, y_train, epochs=50, verbose=1)

model_json=model.to_json()
with open("model.json","w") as json_file:
     json_file.write(model_json)

model.save_weights("model.h5")
print("Saved model to disk")

import tensorflow
from tensorflow.keras.models import model_from_json
json_file1=open('model.json','r')
loaded_model_json=json_file1.read()
json_file1.close()
loaded_model=model_from_json(loaded_model_json)

loaded_model.load_weights("model.h5")

print("Loaded model from disk")
loaded_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])
score=loaded_model.evaluate(X_val,y_test,verbose=0)
print("%s: %.2f%%" % (loaded_model.metrics_names[1],score[1]*100))

def predict_sentiment(text):
  text_seq = tokenizer.texts_to_sequences(text)
  text_pad = tf.keras.utils.pad_sequences(text_seq, maxlen=max_words)

  prediction = model.predict(text_pad).round()
  print(prediction)
  #print(label_encoder.inverse_transform(np.ravel(prediction).astype(int)))
  ind=np.argmax(prediction)
  #list(label_encoder.inverse_transform([0, 1, 2,3,4,5]))
  # if prediction==1.0:
  print(Labels[ind])
  #   print("It is a disaster tweet.")
  # else:
  #   print("It is not a disaster tweet.")

#text="word katandandr food crapilici mkr"
text="black ppl arent expect anyth depend anyth yet"
predict_sentiment([text])

